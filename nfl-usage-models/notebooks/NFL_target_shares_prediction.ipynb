{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyathena import connect\n",
    "from pyathena.pandas_cursor import PandasCursor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "# Define connection to DB\n",
    "conn = connect(\n",
    "    s3_staging_dir='s3://aws-athena-query-results-323906537337-us-east-1/',\n",
    "    region_name='us-east-1',\n",
    "    cursor_class=PandasCursor\n",
    "    )\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # thoughts\n",
    "\n",
    "# Only 2018~2019 seasons contain data for override values, thus for validation purpose.\n",
    "# could consider more seasons without validation data but for building the model purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18855 entries, 0 to 18854\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   season                                  18855 non-null  Int64  \n",
      " 1   week                                    18855 non-null  Int64  \n",
      " 2   gamecode                                18855 non-null  Int64  \n",
      " 3   eventType                               18855 non-null  Int64  \n",
      " 4   teamid                                  18855 non-null  Int64  \n",
      " 5   playerid                                18855 non-null  Int64  \n",
      " 6   positionid                              18855 non-null  Int64  \n",
      " 7   receivertotaltargetsontruepassattempts  18855 non-null  Int64  \n",
      " 8   totaltruepassattempts                   18855 non-null  Int64  \n",
      " 9   targetShare                             18834 non-null  float64\n",
      " 10  Rank                                    18855 non-null  Int64  \n",
      "dtypes: Int64(10), float64(1)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "count    18855.000000\n",
      "mean        31.984673\n",
      "std          8.159212\n",
      "min          0.000000\n",
      "25%         27.000000\n",
      "50%         31.000000\n",
      "75%         37.000000\n",
      "max         64.000000\n",
      "Name: totaltruepassattempts, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    18834.000000\n",
       "mean         0.082664\n",
       "std          0.091931\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.052632\n",
       "75%          0.136364\n",
       "max          0.583333\n",
       "Name: targetShare, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_query = f'''\n",
    "with teamquery as\n",
    "(\n",
    "select season,\n",
    "       eventmetadata.week week,\n",
    "       eventmetadata.gameCode gamecode,  \n",
    "       teamid, \n",
    "       totaltruepassattempts\n",
    "from datalakefootball.team_aggregated_game_stats\n",
    "where season>='2017' and eventmetadata.eventtypeid in (1,2)\n",
    "order by season, week, gamecode, teamid\n",
    ")\n",
    "\n",
    "select\n",
    "    cast(t1.season as integer) season,\n",
    "    t1.eventmetadata.week week,\n",
    "    t1.eventmetadata.gamecode gamecode,\n",
    "    t1.eventmetadata.eventtypeid eventType,\n",
    "    t1.teamid teamid,\n",
    "    t1.player.playerid,\n",
    "    t1.player.positionid,\n",
    "    t1.receivertotaltargetsontruepassattempts,\n",
    "    t2.totaltruepassattempts,\n",
    "    case when t2.totaltruepassattempts = 0 \n",
    "        then null\n",
    "        else t1.receivertotaltargetsontruepassattempts / cast (t2.totaltruepassattempts as double)\n",
    "        end as targetShare,\n",
    "    row_number() over (PARTITION BY\n",
    "                         t1.season, t1.teamid, t1.eventmetadata.week, t1.player.positionid\n",
    "                     ORDER BY\n",
    "                        t1.receivertotaltargetsontruepassattempts DESC) Rank\n",
    "from\n",
    "    datalakefootball.player_aggregated_game_stats as t1\n",
    "    left join\n",
    "    teamquery t2\n",
    "    on t1.season = t2.season and \n",
    "       t1.eventmetadata.gamecode = t2.gamecode and \n",
    "       t1.teamid = t2.teamid\n",
    "where t1.season >= '2017' and \n",
    "     t1.eventmetadata.eventtypeid in (1,2) and\n",
    "     t1.player.positionid in (1,7,9) -- 1:WR, 7:TE, 9:RB\n",
    "order by season, week, gamecode, teamid\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    game_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(game_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "\n",
    "# still some issue with missing data in \"totaltruepassattempts\"\n",
    "#game_df['targetShare'] = game_df.receivertotaltargetsontruepassattempts / game_df.totaltruepassattempts\n",
    "print(game_df.totaltruepassattempts.describe())\n",
    "game_df.targetShare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.head()\n",
    "id = (game_df.season==2019) & (game_df.teamid==323)\n",
    "np.sum(game_df.receivertotaltargetsontruepassattempts[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd=game_df[['season','week','totaltruepassattempts']].groupby(['season','week'])\n",
    "tmp=gd.median()\n",
    "tmp.reset_index(inplace=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = f'''\n",
    "select -- season,\n",
    "       -- eventmetadata.week week,\n",
    "       -- eventmetadata.gameCode gamecode,  \n",
    "       -- teamid, \n",
    "       sum(totaltruepassattempts)\n",
    "from datalakefootball.team_aggregated_game_stats\n",
    "where season='2019' and eventmetadata.eventtypeid in (1,2) and\n",
    "    teamid = 323\n",
    "-- order by season, week, gamecode, teamid\n",
    "'''\n",
    "\n",
    "team_df = cursor.execute(simple_query).as_pandas()\n",
    "\n",
    "team_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Expected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16687 entries, 0 to 16686\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   gamecode         16687 non-null  Int64  \n",
      " 1   playerid         16687 non-null  Int64  \n",
      " 2   exp_targetShare  16687 non-null  float64\n",
      "dtypes: Int64(2), float64(1)\n",
      "memory usage: 423.8 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18855 entries, 0 to 18854\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   season                                  18855 non-null  Int64  \n",
      " 1   week                                    18855 non-null  Int64  \n",
      " 2   gamecode                                18855 non-null  Int64  \n",
      " 3   eventType                               18855 non-null  Int64  \n",
      " 4   teamid                                  18855 non-null  Int64  \n",
      " 5   playerid                                18855 non-null  Int64  \n",
      " 6   positionid                              18855 non-null  Int64  \n",
      " 7   receivertotaltargetsontruepassattempts  18855 non-null  Int64  \n",
      " 8   totaltruepassattempts                   18855 non-null  Int64  \n",
      " 9   targetShare                             18834 non-null  float64\n",
      " 10  Rank                                    18855 non-null  Int64  \n",
      " 11  exp_targetShare                         11706 non-null  float64\n",
      "dtypes: Int64(10), float64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "# we only have 2 years data 2018 ~ 2019 for research purpose\n",
    "\n",
    "simple_query = f'''\n",
    "select \n",
    "    eventmetadata.gamecode,\n",
    "    player.playerid,\n",
    "    targetpercentage exp_targetShare\n",
    "from datalakefootball.player_expected_rates\n",
    "where \n",
    "    season >= '2017' and \n",
    "    eventmetadata.eventtypeid in (1,2) and\n",
    "    player.positionid in (1,7,9) and version='override'\n",
    "order by season\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    exp_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(exp_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "# merge expected value (override version) into player game stats\n",
    "# Note that 2018 season missing about 20% records as well!\n",
    "# when we do model calibration, only the data entry with exp_values should be used!\n",
    "\n",
    "game_df = pd.merge(game_df, exp_df, on=['gamecode','playerid'], how='left')\n",
    "game_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Ytd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18855 entries, 0 to 18854\n",
      "Data columns (total 12 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   season                              18855 non-null  Int64  \n",
      " 1   week                                18855 non-null  Int64  \n",
      " 2   gamecode                            18855 non-null  Int64  \n",
      " 3   teamid                              18855 non-null  Int64  \n",
      " 4   playerid                            18855 non-null  Int64  \n",
      " 5   positionid                          18855 non-null  Int64  \n",
      " 6   ytd_onFieldTotalTruePassAttempts    17212 non-null  Int64  \n",
      " 7   ytd_totalTargetsOnTruePassAttempts  17212 non-null  Int64  \n",
      " 8   game_totaltruepassattempts          18855 non-null  Int64  \n",
      " 9   ytd_rank                            18855 non-null  Int64  \n",
      " 10  ytd_totaltruepassattempts           17212 non-null  Int64  \n",
      " 11  ytd_targetShare                     17211 non-null  float64\n",
      "dtypes: Int64(11), float64(1)\n",
      "memory usage: 1.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "simple_query = f'''\n",
    "with teamquery as\n",
    "(\n",
    "select eventmetadata.gameCode gamecode,  \n",
    "       teamid, \n",
    "       totaltruepassattempts game_totalTruePassAttempts\n",
    "from datalakefootball.team_aggregated_game_stats\n",
    "where season>='2017' and eventmetadata.eventtypeid in (1,2)\n",
    ")\n",
    "\n",
    "select \n",
    "  cast(t1.season as integer) season, \n",
    "  t1.eventmetadata.week, \n",
    "  t1.eventmetadata.gamecode, \n",
    "  t1.teamid,\n",
    "  t1.player.playerid,\n",
    "  t1.player.positionid,\n",
    "  t1.onfieldtotaltruepassattempts ytd_onFieldTotalTruePassAttempts,\n",
    "  t1.receivertotaltargetsontruepassattempts ytd_totalTargetsOnTruePassAttempts,\n",
    "  t2.game_totaltruepassattempts,\n",
    "  row_number() over (PARTITION BY\n",
    "                         t1.season, t1.teamid, t1.eventmetadata.week, t1.player.positionid\n",
    "                     ORDER BY\n",
    "                         t1.receivertotaltargetsontruepassattempts DESC) ytd_rank\n",
    "from datalakefootball.player_aggregated_ytd_stats t1\n",
    "    left join teamquery t2\n",
    "    on t1.eventmetadata.gamecode = t2.gamecode and \n",
    "       t1.teamid=t2.teamid\n",
    "where \n",
    "    t1.season >='2017' and \n",
    "    t1.player.positionid in (1,7,9) and \n",
    "    t1.eventmetadata.eventtypeid in (1,2) and\n",
    "    t1.eventmetadata.week is not null -- when a week is missing, the player may not be active\n",
    "order by season, week, gamecode, teamid\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    ytd_df = cursor.execute(simple_query).as_pandas()\n",
    "    #print(ytd_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "    \n",
    "# prepare ytd_truepassattempts for each player. in this way, no update for missed games\n",
    "gd = ytd_df.groupby(['season','playerid'])\n",
    "\n",
    "ytd_df['ytd_totaltruepassattempts'] = gd.game_totaltruepassattempts.cumsum()\n",
    "ytd_df['ytd_totaltruepassattempts'] = gd.ytd_totaltruepassattempts.shift(1)\n",
    "\n",
    "ytd_df['ytd_targetShare'] = ytd_df.ytd_totalTargetsOnTruePassAttempts / ytd_df.ytd_totaltruepassattempts\n",
    "print(ytd_df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = (ytd_df.ytd_totaltruepassattempts == 0) |\n",
    "np.sum(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18855 entries, 0 to 18854\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   season                                  18855 non-null  Int64  \n",
      " 1   week                                    18855 non-null  Int64  \n",
      " 2   gamecode                                18855 non-null  Int64  \n",
      " 3   eventType                               18855 non-null  Int64  \n",
      " 4   teamid                                  18855 non-null  Int64  \n",
      " 5   playerid                                18855 non-null  Int64  \n",
      " 6   positionid                              18855 non-null  Int64  \n",
      " 7   receivertotaltargetsontruepassattempts  18855 non-null  Int64  \n",
      " 8   totaltruepassattempts                   18855 non-null  Int64  \n",
      " 9   targetShare                             18834 non-null  float64\n",
      " 10  Rank                                    18855 non-null  Int64  \n",
      " 11  exp_targetShare                         11706 non-null  float64\n",
      " 12  ytd_rank                                18855 non-null  Int64  \n",
      " 13  ytd_onFieldTotalTruePassAttempts        17212 non-null  Int64  \n",
      " 14  ytd_totalTargetsOnTruePassAttempts      17212 non-null  Int64  \n",
      " 15  ytd_totaltruepassattempts               17212 non-null  Int64  \n",
      " 16  ytd_targetShare                         17211 non-null  float64\n",
      "dtypes: Int64(14), float64(3)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "# merge ytd data into game data\n",
    "game_df = pd.merge(game_df, ytd_df[['gamecode','playerid',\n",
    "                                    'ytd_rank',\n",
    "                                   'ytd_onFieldTotalTruePassAttempts',\n",
    "                                   'ytd_totalTargetsOnTruePassAttempts',\n",
    "                                   'ytd_totaltruepassattempts',\n",
    "                                   'ytd_targetShare']], \n",
    "                    on=['gamecode','playerid'], how='left')\n",
    "game_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Prepare ytd data by position rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ytd targetShare by position rank\n",
    "# only ytd data is used, no baseline information is used!\n",
    "\n",
    "rank_df = game_df[['season','week','gamecode','teamid','playerid','positionid',\n",
    "                   'receivertotaltargetsontruepassattempts','totaltruepassattempts','Rank']].copy()\n",
    "\n",
    "gd = rank_df.groupby(['season','teamid','positionid','Rank'])\n",
    "\n",
    "rank_df['ytd_targetShareByPositionRank'] = gd.receivertotaltargetsontruepassattempts.cumsum() / \\\n",
    "                                        gd.totaltruepassattempts.cumsum()\n",
    "rank_df['ytd_targetShareByPositionRank'] = gd.ytd_targetShareByPositionRank.shift(1)\n",
    "\n",
    "rank_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Identify weekly injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify weekly injury and adjust ytd_targetShare accordingly\n",
    "\n",
    "# example:\n",
    "# Calvin Ridley (884013), Atlanta Falcon (323), 2019 game 14 out -> what impact on other WR\n",
    "# 822014, previously ranked 3rd, now move to #2 for game #14 ~ #17\n",
    "## what if 884013 is not out right after game #14?\n",
    "# the ytd for 822014 is much lower before game #14, it would be better if we use byRank value instead for \n",
    "# the rest of the season\n",
    "# a step further is to use a combo of reset ytd and byRank value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate target share by ranks for each positin type when there is a roster change\n",
    "# return a list of objects, each object contains targetShares for players for a game when roster change happens\n",
    "# Note: there is a bias to use targetShare by position to estimate each player's performance!!!\n",
    "\n",
    "def calculateTargetShareAdjByRank(game_df, positionIds, seasons, rank_df, printDetails=False):\n",
    "\n",
    "    adjustedRates = []\n",
    "    \n",
    "    teams = game_df.teamid.unique()\n",
    "\n",
    "    for season in seasons:\n",
    "        for team in teams:\n",
    "            for positionId in positionIds:\n",
    "                #print(team)\n",
    "\n",
    "                id = (game_df.season==season) & (game_df.teamid==team) & (game_df.positionid==positionId)\n",
    "                one_team = game_df[id]\n",
    "\n",
    "                #print(one_team.shape)\n",
    "\n",
    "                ranking_data = []\n",
    "\n",
    "                for i,week in enumerate(one_team.week.unique()):\n",
    "                    id = one_team.week == week\n",
    "\n",
    "                    if i == 0:\n",
    "                        ranking_data = one_team.loc[id, ['receivertotaltargetsontruepassattempts','playerid']].copy()\n",
    "                        ranking_data['ytd_rank'] = -1\n",
    "                        ranking_data.set_index('playerid', inplace=True)\n",
    "                        continue\n",
    "\n",
    "                    data = one_team.loc[id, ['teamid','gamecode','positionid','playerid',\n",
    "                                        'receivertotaltargetsontruepassattempts']].copy()\n",
    "                    data.set_index('playerid', inplace=True)\n",
    "\n",
    "                    # add according to playerid index\n",
    "                    ranking_data = ranking_data.add(data, fill_value=0)\n",
    "                    ranking_data.sort_values('receivertotaltargetsontruepassattempts', inplace=True, ascending=False)\n",
    "                    ranking_data.loc[:,'ytd_rank'] = np.arange(len(ranking_data)) + 1\n",
    "\n",
    "                    current_week_data = one_team[one_team.week == week]\n",
    "\n",
    "                    #check if any top (2) players is missing for this week\n",
    "                    missingPlayers = [player for player in ranking_data.index.values\n",
    "                                     if player not in current_week_data.playerid.values and\n",
    "                                        ranking_data.loc[player].ytd_rank <= 2]\n",
    "\n",
    "                    if missingPlayers:\n",
    "                        if printDetails:\n",
    "                            for player in missingPlayers:\n",
    "                                print(week, player, ranking_data.loc[player].ytd_rank)\n",
    "\n",
    "                        # re-arrange ranks of active players to reflect currently predicted rank\n",
    "                        data['onFieldRank'] = ranking_data.loc[data.index].ytd_rank.\\\n",
    "                                                rank(method='first', na_option='bottom')\n",
    "                        data = data.astype({'onFieldRank':'int64'})\n",
    "                        data.reset_index(inplace=True)\n",
    "\n",
    "                        # merge target%_by_rank into data\n",
    "                        data = pd.merge(data, \n",
    "                                        rank_df[['teamid','gamecode','positionid','Rank',\n",
    "                                                 'ytd_targetShareByPositionRank']], \n",
    "                                        left_on=['teamid','gamecode','positionid','onFieldRank'],\n",
    "                                        right_on=['teamid','gamecode','positionid','Rank'], how='left')\n",
    "                        \n",
    "                        # adjustment\n",
    "                        #data.ytd_targetShareByPositionRank = data.ytd_targetShareByPositionRank * 0.9\n",
    "\n",
    "                        adjustedRates.append(data)\n",
    "\n",
    "    return(adjustedRates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = calculateTargetShareAdjByRank(game_df, positionIds=[1,7,9], seasons=[2017, 2018,2019])\n",
    "\n",
    "adjustedRates = pd.concat(re, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = pd.merge(game_df, \n",
    "                 adjustedRates[['teamid','gamecode','playerid','onFieldRank','ytd_targetShareByPositionRank']], \n",
    "                 on=['teamid','gamecode','playerid'], \n",
    "                 how='left')\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a new column 'ytd_targetShareAdj' column to contain ytd data with adjustment by injury situation\n",
    "game_df['ytd_targetShareAdj'] = game_df.ytd_targetShare\n",
    "\n",
    "id = game_df.ytd_targetShareByPositionRank.isnull()\n",
    "game_df.ytd_targetShareAdj[~id] = game_df.ytd_targetShareByPositionRank[~id] \n",
    "\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method has some improvement from ytd baseline\n",
    "\n",
    "id1 = (game_df.season.isin([2018,2019])) & (game_df.positionid.isin([1,7,9]))\n",
    "id2 = game_df.ytd_targetShareByPositionRank.isnull()\n",
    "\n",
    "print(abs(game_df[id1 & ~id2].targetShare - game_df[id1 & ~id2].exp_targetShare).mean())\n",
    "\n",
    "print(abs(game_df[id1 & ~id2].targetShare - game_df[id1 & ~id2].ytd_targetShare).mean())\n",
    "\n",
    "print(abs(game_df[id1 & ~id2].targetShare - game_df[id1 & ~id2].ytd_targetShareByPositionRank).mean(),'\\n')\n",
    "\n",
    "id = (~game_df.ytd_targetShare.isnull()) & (~game_df.ytd_targetShareAdj.isnull()) & \\\n",
    "    (game_df.season.isin([2018,2019])) & (game_df.positionid.isin([1,7,9]))\n",
    "\n",
    "print(abs(game_df.targetShare - game_df.exp_targetShare)[id].mean())\n",
    "\n",
    "print(abs(game_df.targetShare - game_df.ytd_targetShare)[id].mean())\n",
    "\n",
    "print(abs(game_df.targetShare - game_df.ytd_targetShareAdj)[id].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6 Prepare baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create baseline case from ytd data\n",
    "\n",
    "baseline_df = game_df[['season','playerid','ytd_onFieldTotalTruePassAttempts',\n",
    "                       'ytd_totalTargetsOnTruePassAttempts','ytd_totaltruepassattempts',\n",
    "                       'ytd_targetShare','ytd_targetShareAdj']].copy()\n",
    "baseline_df = baseline_df.groupby(['season','playerid']).tail(1)\n",
    "\n",
    "baseline_df.rename(columns={'ytd_onFieldTotalTruePassAttempts':'base_onFieldTotalTruePassAttempts',\n",
    "                            'ytd_totalTargetsOnTruePassAttempts':'base_totalTargetsOnTruePassAttempts',\n",
    "                            'ytd_totaltruepassattempts':'base_totaltruepassattempts',\n",
    "                            'ytd_targetShare':'base_targetShare',\n",
    "                            'ytd_targetShareAdj':'base_targetShareAdj'},\n",
    "                                inplace=True)\n",
    "\n",
    "baseline_df.season = baseline_df.season + 1\n",
    "\n",
    "# merge baseline info into game_df, in this case, we will lose 2017\n",
    "\n",
    "game_df = pd.merge(game_df, baseline_df, on=['season','playerid'], how='left')\n",
    "game_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = game_df.season.isin([2018, 2019])\n",
    "game_df = game_df[id]\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Featuring preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy in case we need to re-run the following steps\n",
    "tmp = game_df.copy()\n",
    "#game_df = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.ytd_targetShareByPositionRank.fillna(-1, inplace=True)\n",
    "\n",
    "game_df.fillna(0, inplace=True)\n",
    "\n",
    "print(game_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted historical values\n",
    "# note the fill of na is after the target percentage has been calculated\n",
    "\n",
    "alpha = 5.0\n",
    "\n",
    "w = game_df.ytd_onFieldTotalTruePassAttempts * alpha / \\\n",
    "        (game_df.ytd_onFieldTotalTruePassAttempts * alpha + game_df.base_onFieldTotalTruePassAttempts)\n",
    "\n",
    "id = (game_df.ytd_onFieldTotalTruePassAttempts==0) & (game_df.base_onFieldTotalTruePassAttempts==0)\n",
    "w[id] = 1.0\n",
    "\n",
    "game_df['w_targetShareAdj'] = game_df.ytd_targetShareAdj * w + game_df.base_targetShare * (1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(game_df.isna().any(axis=1))\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.season.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.ytd_rank = game_df.ytd_rank.astype('float64')\n",
    "\n",
    "num_fields = [\n",
    "                'w_targetShareAdj',\n",
    "                'ytd_rank'\n",
    "             ]\n",
    "\n",
    "cat_fields = [\n",
    "                #'eventType',\n",
    "                #'teamid',\n",
    "                'positionid',\n",
    "             ]\n",
    "              \n",
    "label = game_df.targetShare\n",
    "\n",
    "# StandardScaler version\n",
    "transform_pipeline = ColumnTransformer(transformers=[\n",
    "                                            #('num', StandardScaler(), num_fields),\n",
    "                                            ('num', 'passthrough', num_fields),\n",
    "                                            ('cat', OneHotEncoder(categories='auto'), cat_fields)\n",
    "                                        ])\n",
    "features_transformed = transform_pipeline.fit_transform(game_df)\n",
    "\n",
    "\n",
    "# None-StandardScaler version\n",
    "transform_pipeline_2 = ColumnTransformer(transformers=[\n",
    "                                            #('num', StandardScaler(), num_fields),\n",
    "                                            ('num', 'passthrough', num_fields),\n",
    "                                            ('cat', OneHotEncoder(categories='auto'), cat_fields)\n",
    "                                        ])\n",
    "features_transformed_2 = transform_pipeline_2.fit_transform(game_df)\n",
    "\n",
    "feature_names = num_fields\n",
    "feature_names.extend(transform_pipeline_2.named_transformers_.cat.get_feature_names(input_features=cat_fields))\n",
    "print(feature_names)\n",
    "\n",
    "if type(features_transformed_2) == np.ndarray:\n",
    "    features_transformed_2 = pd.DataFrame(features_transformed_2, columns=feature_names)\n",
    "else:\n",
    "    features_transformed_2 = pd.DataFrame(features_transformed_2.toarray(), columns=feature_names)\n",
    "\n",
    "#cat_one_hot_fields = list(transform_pipeline.named_transformers_.cat.get_feature_names())\n",
    "pd.DataFrame(features_transformed).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBenchmarkModelPerformance(data, positionId):\n",
    "    id = data.positionid.isin(positionId)\n",
    "    \n",
    "    data_df = data[id].copy()\n",
    "    \n",
    "    print(data_df.targetShare.describe(), '\\n')\n",
    "    \n",
    "    re = (data_df.targetShare - data_df.exp_targetShare)\n",
    "    r2 = 1 - sum(re**2)/sum((data_df.targetShare - np.mean(data_df.targetShare))**2)\n",
    "    print(\"                    {}     {}\".format('MAE', 'R2') )\n",
    "    print(\"Override model:     {:.4f}  {:.1%}\".format(abs(re).mean(), r2) )\n",
    "\n",
    "    re = (data_df.targetShare - data_df.ytd_targetShare)\n",
    "    r2 = 1 - sum(re**2)/sum((data_df.targetShare - np.mean(data_df.targetShare))**2)\n",
    "    print(\"ytd model:          {:.4f}  {:.1%}\".format(abs(re).mean(), r2) )\n",
    "\n",
    "    re = (data_df.targetShare - data_df.w_targetShareAdj)\n",
    "    r2 = 1 - sum(re**2)/sum((data_df.targetShare - np.mean(data_df.targetShare))**2)\n",
    "    print(\"Weighted ytd model: {:.4f}, {:.1%}\".format(abs(re).mean(), r2) )\n",
    "    \n",
    "    #re = (data_df.rushingShare - data_df.w_rushingShareAdj_norm)\n",
    "    #r2 = 1 - sum(re**2)/sum((data_df.rushingShare - np.mean(data_df.rushingShare))**2)\n",
    "    #print(\"W/N ytd model:      {:.4f}, {:.1%}\".format(abs(re).mean(), r2) )\n",
    "\n",
    "    return()\n",
    "\n",
    "print(\"Target share summary:\")\n",
    "printBenchmarkModelPerformance(game_df, [1,7,9])\n",
    "\n",
    "print(\"\\nTarget share summary for WRs:\")\n",
    "printBenchmarkModelPerformance(game_df, [1])\n",
    "\n",
    "print(\"\\nTarget share summary for TEs:\")\n",
    "printBenchmarkModelPerformance(game_df, [7])\n",
    "\n",
    "print(\"\\nTarget share summary for RBs:\")\n",
    "printBenchmarkModelPerformance(game_df, [9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate models\n",
    "MAE = make_scorer(mean_absolute_error)\n",
    "folds = 5\n",
    "\n",
    "model_linear = SGDRegressor(max_iter=10000, tol=1e-4)\n",
    "\n",
    "model_svr = LinearSVR(random_state=42, tol=1e-6, max_iter=10000)\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=200, max_depth=30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean absolute error:' )\n",
    "\n",
    "MAE_linear = cross_val_score(model_linear,\n",
    "    features_transformed,\n",
    "    label,\n",
    "    cv=folds,\n",
    "    scoring=MAE)\n",
    "#print('Linear regression: {:.4f}'.format(np.mean(MAE_linear)))\n",
    "R2_linear = cross_val_score(model_linear,\n",
    "    features_transformed,\n",
    "    label,\n",
    "    cv=folds,\n",
    "    scoring=('r2'))\n",
    "print('Linear regression: {:.4f}  {:.1%}'.format(np.mean(MAE_linear), np.mean(R2_linear)))\n",
    "\n",
    "\n",
    "MAE_rf = cross_val_score(model_rf,\n",
    "    features_transformed_2,\n",
    "    label,\n",
    "    cv=folds,\n",
    "    scoring=MAE)\n",
    "#print('RF regression:     {:.4f}'.format(np.mean(MAE_rf)))\n",
    "R2_rf = cross_val_score(model_rf,\n",
    "    features_transformed_2,\n",
    "    label,\n",
    "    cv=folds,\n",
    "    scoring=('r2'))\n",
    "print('RF regression:     {:.4f}  {:.1%}'.format(np.mean(MAE_rf), np.mean(R2_rf)))\n",
    "\n",
    "MAE_svr = cross_val_score(model_svr,\n",
    "    features_transformed,\n",
    "    label,\n",
    "    cv=folds,\n",
    "    scoring=MAE)\n",
    "#print('SV regression:     {:.4f}'.format(np.mean(MAE_svr)))\n",
    "R2_svr = cross_val_score(model_svr,\n",
    "    features_transformed,\n",
    "    label,\n",
    "    cv=folds,\n",
    "    scoring=('r2'))\n",
    "print('SV regression:     {:.4f}  {:.1%}'.format(np.mean(MAE_svr), np.mean(R2_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance study\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=200, max_depth=20, random_state=0)\n",
    "regr.fit(features_transformed, label)\n",
    "\n",
    "cat_one_hot_fields = list(transform_pipeline.named_transformers_.cat.get_feature_names())\n",
    "feature_score = pd.DataFrame([feature_names,regr.feature_importances_], \n",
    "                             index=['feature','importance']).transpose()\n",
    "feature_score.sort_values(by='importance',ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model interpretation\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "mod = sm.OLS(np.array(label), features_transformed_2, missing='drop')\n",
    "res = mod.fit()\n",
    "\n",
    "mae = np.abs(res.resid).mean()\n",
    "\n",
    "print('{:.3f}'.format(mae) )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_svr.fit(features_transformed, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9,9])\n",
    "plt.plot(game_df.targetShare, res.predict(features_transformed), 'o')\n",
    "plt.xlabel('target share')\n",
    "plt.xlim(0.0, 0.65)\n",
    "plt.ylabel('prediction')\n",
    "plt.ylim(0.0, 0.65)\n",
    "plt.plot( [0,1],[0,1] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df['fitted_targetShare']=res.fittedvalues.values\n",
    "game_df.to_csv(\"target_share_modeling_results.csv\")\n",
    "game_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Large error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = (game_df.targetShare - game_df.w_targetShareAdj > 0.25) & (game_df.season == 2019)\n",
    "sum(id)\n",
    "game_df[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study how much normalization is needed for target shares (sum of all target shares should be near 100%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl-usage-models",
   "language": "python",
   "name": "nfl-usage-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
