{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyathena import connect\n",
    "from pyathena.pandas_cursor import PandasCursor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define connection to DB\n",
    "conn = connect(\n",
    "    s3_staging_dir='s3://aws-athena-query-results-323906537337-us-east-1/',\n",
    "    region_name='us-east-1',\n",
    "    cursor_class=PandasCursor\n",
    "    )\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4250 entries, 0 to 4249\n",
      "Data columns (total 15 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   season                          4250 non-null   Int64  \n",
      " 1   teamid                          4250 non-null   Int64  \n",
      " 2   week                            4250 non-null   Int64  \n",
      " 3   gamecode                        4250 non-null   Int64  \n",
      " 4   gametimeinseconds               4250 non-null   float64\n",
      " 5   timeofpossessioninseconds       4250 non-null   float64\n",
      " 6   totalplaysonfield               4250 non-null   Int64  \n",
      " 7   totaloffensiveplays             4250 non-null   Int64  \n",
      " 8   totaloffensiveplays_normalized  4250 non-null   float64\n",
      " 9   totaldesignedpassplays          4250 non-null   Int64  \n",
      " 10  totalpassattempts               4250 non-null   Int64  \n",
      " 11  totalrushingattempts            4250 non-null   Int64  \n",
      " 12  totalsacksallowed               4250 non-null   Int64  \n",
      " 13  totalthrowawaysandspikes        4250 non-null   Int64  \n",
      " 14  totalscrambles                  4250 non-null   Int64  \n",
      "dtypes: Int64(12), float64(3)\n",
      "memory usage: 548.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# query team game-level stats\n",
    "\n",
    "simple_query = f'''\n",
    "select \n",
    "       cast(season as integer) season,\n",
    "       teamid,\n",
    "       eventmetadata.week as week,\n",
    "       eventmetadata.gameCode as gamecode,\n",
    "       gametimeinseconds,\n",
    "       timeofpossessioninseconds,\n",
    "       totalplaysonfield,\n",
    "       totaloffensiveplays,\n",
    "       totaloffensiveplays * 3600 / gametimeinseconds as totaloffensiveplays_normalized,\n",
    "       totaldesignedpassplays as totaldesignedpassplays,\n",
    "       totalpassattempts as totalpassattempts,\n",
    "       -- totalexpectedpassingplays, -- no value\n",
    "       -- passingpercentage,\n",
    "       totalrushingattempts,\n",
    "       totalsacksallowed,\n",
    "       totalthrowawaysandspikes,\n",
    "       totalscrambles\n",
    "       -- totalsacks,\n",
    "       -- timeofpossessionpergameinminutes, -- normalized into a 60-min game?\n",
    "       -- timeofpossessioninminutes,  \n",
    "from datalakefootball.team_aggregated_game_stats\n",
    "where \n",
    "    eventmetadata.week is not null\n",
    "    and eventmetadata.eventtypeid < 3\n",
    "order by season, teamid, week\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    game_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(game_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "# totaloffensiveplays = totalrushingattempts + totalpassattempts + totalsacksallowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8492 entries, 0 to 8491\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   season               8492 non-null   object        \n",
      " 1   date                 8492 non-null   datetime64[ns]\n",
      " 2   week                 8492 non-null   Int64         \n",
      " 3   game_code            8492 non-null   Int64         \n",
      " 4   event_type_id        8492 non-null   Int64         \n",
      " 5   home_team_id         8492 non-null   Int64         \n",
      " 6   team1                8492 non-null   object        \n",
      " 7   home_team_score      8492 non-null   Int64         \n",
      " 8   away_team_id         8492 non-null   Int64         \n",
      " 9   team2                8492 non-null   object        \n",
      " 10  away_team_score      8492 non-null   Int64         \n",
      " 11  home_team_prev_week  8492 non-null   Int64         \n",
      " 12  away_team_prev_week  8492 non-null   Int64         \n",
      "dtypes: Int64(9), datetime64[ns](1), object(3)\n",
      "memory usage: 937.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# from datalake football to query game level information\n",
    "# query team game-level stats\n",
    "\n",
    "simple_query = f'''\n",
    "-- t1 and t2: ceate one record per game from pbp data\n",
    "with t1 as\n",
    "(\n",
    "select\n",
    "  ROW_NUMBER() OVER(partition by eventmetadata.gamecode) AS num_row, \n",
    "  season, eventmetadata, teammetadata\n",
    "from datalakefootball.pbp\n",
    "where leagueid='8'\n",
    "),\n",
    "\n",
    "t2 as\n",
    "(\n",
    "select\n",
    "  season,\n",
    "  cast(FROM_UNIXTIME(eventmetadata.gamedateutcepoch) as DATE) date,\n",
    "  eventmetadata.week, \n",
    "  eventmetadata.gamecode game_code, eventmetadata.eventtypeid as event_type_id,\n",
    "  teammetadata[1].teamid home_team_id, \n",
    "  teammetadata[1].abbreviation team1,\n",
    "  teammetadata[1].score home_team_score,\n",
    "  teammetadata[2].teamid away_team_id, \n",
    "  teammetadata[2].abbreviation team2,\n",
    "  teammetadata[2].score away_team_score\n",
    "from t1\n",
    "where num_row=1\n",
    "order by game_code\n",
    "),\n",
    "\n",
    "-- t3 and t4 are created to decide previous game week for each team\n",
    "t3 as\n",
    "(\n",
    "select\n",
    "  *,\n",
    "  ROW_NUMBER() OVER(partition by season, team_id order by week) AS num_row\n",
    "from\n",
    "  (select * from (select season, home_team_id as team_id, week from t2)\n",
    "   union\n",
    "   select * from (select season, away_team_id as team_id, week from t2))\n",
    "),\n",
    "\n",
    "t4 as\n",
    "(\n",
    "select c.season, c.team_id, c.week, p.week prev_week\n",
    "from t3 as c\n",
    "  left join t3 as p\n",
    "  on c.season=p.season and c.team_id=p.team_id and c.num_row=p.num_row+1\n",
    " order by c.season, c.team_id, c.week\n",
    ")\n",
    "\n",
    "-- final game level table\n",
    "select \n",
    "  t2.*, \n",
    "  COALESCE(home_table.prev_week,0) as home_team_prev_week,\n",
    "  COALESCE(away_table.prev_week,0) as away_team_prev_week\n",
    "from t2 \n",
    "  left join t4 as home_table\n",
    "  on t2.season=home_table.season and t2.home_team_id=home_table.team_id and t2.week=home_table.week\n",
    "  left join t4 as away_table\n",
    "  on t2.season=away_table.season and t2.away_team_id=away_table.team_id and t2.week=away_table.week\n",
    "order by t2.season, t2.week\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    game_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(game_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "# totaloffensiveplays = totalrushingattempts + totalpassattempts + totalsacksallowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 expected game data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.2 expected total plays: version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load expected game data of version 1\n",
    "\n",
    "simple_query = f'''\n",
    "select \n",
    "   cast(season as integer) season, \n",
    "   team.teamid as teamid,\n",
    "   opponentteamid,\n",
    "   eventmetadata.week as week,\n",
    "   totalplays as exp_totalPlays\n",
    "   -- passingplays as exp_passingPlays, -- no values\n",
    "   -- rushingplays as exp_rushingPlays\n",
    "from datalakefootball.team_expected_rates\n",
    "where \n",
    "    season >= '2015'\n",
    "    and version = '1' \n",
    "    and (eventmetadata.eventtypeid = 1 or eventmetadata.eventtypeid = 2)\n",
    "order by season, teamid, week\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    exp_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(exp_df.info())\n",
    "    #plt.plot(exp_df.exp_totalPlays)\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "\n",
    "# merge expected game info\n",
    "game_df = pd.merge(game_df, exp_df, on=['season','teamid','week'], how='inner')\n",
    "print(game_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 ytd data (pre-game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = f'''\n",
    "select\n",
    "    cast(season as integer) season,\n",
    "    teamid,\n",
    "    eventmetadata.week as week, \n",
    "    gametimeinseconds as ytd_gameTime,\n",
    "    totaloffensiveplays as ytd_totalPlays,\n",
    "    totaldesignedpassplays / floor(gametimeinseconds / 3600) as ytd_passPlaysPerGame, -- overtime is estimated as well\n",
    "    pace as ytd_pace,\n",
    "    timeofpossessioninseconds as ytd_TOP,\n",
    "    timeofpossessioninseconds / floor(gametimeinseconds / 3600) as ytd_TOPperGame, -- consider ot\n",
    "    passingpercentage as ytd_passingpercentage,\n",
    "\n",
    "    totalpoints / floor(gametimeinseconds / 3600) as ytd_totalPointsPerGame,  -- consider ot\n",
    "    totalsacks / floor(gametimeinseconds / 3600) as ytd_totalSacksPerGame     -- consider ot\n",
    "    \n",
    "from datalakefootball.team_aggregated_ytd_stats\n",
    "where \n",
    "    season >= '2013' \n",
    "    and (eventmetadata.eventtypeid = 1 or eventmetadata.eventtypeid = 2)\n",
    "    and eventmetadata.week is not null\n",
    "order by season, teamid, week\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    ytd_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(ytd_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "ytd_df['ytd_offensivePlaysPerGame'] = ytd_df.ytd_TOPperGame / ytd_df.ytd_pace\n",
    "    \n",
    "# merge ytd data into game_data\n",
    "game_df = pd.merge(game_df, ytd_df, on=['season','teamid','week'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = f'''\n",
    "select\n",
    "    cast(season as integer) season,\n",
    "    teamid,\n",
    "    eventmetadata.week as week, \n",
    "    pace as ytd_pace_conceded\n",
    "from datalakefootball.team_aggregated_ytd_stats_conceded\n",
    "where \n",
    "    season >= '2013' \n",
    "    and (eventmetadata.eventtypeid = 1 or eventmetadata.eventtypeid = 2)\n",
    "    and eventmetadata.week is not null\n",
    "order by season, teamid, week\n",
    "'''\n",
    "if True:\n",
    "    ytd_df_conceded = cursor.execute(simple_query).as_pandas()\n",
    "    print(ytd_df_conceded.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "game_df = pd.merge(game_df, ytd_df_conceded, on=['season','teamid','week'], how='left')\n",
    "game_df.info()\n",
    "\n",
    "\n",
    "# add opponent ytd_data\n",
    "tmp = game_df[['season','teamid','week','ytd_pace','ytd_pace_conceded','ytd_offensivePlaysPerGame']].copy()\n",
    "tmp.rename(columns={'teamid':'opponentteamid', \n",
    "                    'ytd_pace':'ytd_o_pace', \n",
    "                    'ytd_pace_conceded':'ytd_o_pace_conceded',\n",
    "                    'ytd_offensivePlaysPerGame':'ytd_o_offensivePlaysPerGame'}, inplace=True)\n",
    "game_df = pd.merge(game_df, tmp, on=['season','opponentteamid','week'], how='left')\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3.1 ytd_yards_per_rush / passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = f'''\n",
    "select cast(season as integer) season, \n",
    "       teamid, eventmetadata.gameCode gamecode, eventmetadata.week week, \n",
    "       passing.attempts passingAttempts, \n",
    "       passing.yards passingYards,\n",
    "       rushing.attempts rushingAttempts, \n",
    "       rushing.yards rushingYards\n",
    "from datalakefootball.team_stats_game\n",
    "where season>='2013' and (eventmetadata.eventtypeid=1 or eventmetadata.eventtypeid=2)\n",
    "order by season, teamid, week\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    yards_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(yards_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "\n",
    "# merge exp_df into yards_df to give it opponent_team_id\n",
    "\n",
    "yards_df = pd.merge(yards_df, game_df[['season','teamid','gamecode','opponentteamid']], \n",
    "                    on=['season','teamid','gamecode'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cumulated sum and then yardsPerAttempt\n",
    "gd = yards_df.groupby(['season','teamid'])\n",
    "\n",
    "yards_df['ytd_passingYardsPerAttempt'] = gd.passingYards.cumsum() / gd.passingAttempts.cumsum()\n",
    "yards_df['ytd_rushingYardsPerAttempt'] = gd.rushingYards.cumsum() / gd.rushingAttempts.cumsum()\n",
    "\n",
    "yards_df['ytd_passingYardsPerAttempt'] = gd.ytd_passingYardsPerAttempt.shift(1)\n",
    "yards_df['ytd_rushingYardsPerAttempt'] = gd.ytd_rushingYardsPerAttempt.shift(1)\n",
    "\n",
    "# calculate opponent cumulated sum and then yardsPerAttempt\n",
    "yards_df.sort_values(['season','opponentteamid','week'], inplace=True)\n",
    "\n",
    "gd = yards_df.groupby(['season','opponentteamid'])\n",
    "\n",
    "yards_df['ytd_o_passingYardsPerAttempt_conceded'] = gd.passingYards.cumsum() / gd.passingAttempts.cumsum()\n",
    "yards_df['ytd_o_rushingYardsPerAttempt_conceded'] = gd.rushingYards.cumsum() / gd.rushingAttempts.cumsum()\n",
    "\n",
    "yards_df['ytd_o_passingYardsPerAttempt_conceded'] = gd.ytd_o_passingYardsPerAttempt_conceded.shift(1)\n",
    "yards_df['ytd_o_rushingYardsPerAttempt_conceded'] = gd.ytd_o_rushingYardsPerAttempt_conceded.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to get team conceded yards\n",
    "tmp = yards_df[['season', 'opponentteamid', 'week',\n",
    "                       'ytd_o_passingYardsPerAttempt_conceded','ytd_o_rushingYardsPerAttempt_conceded']]\n",
    "\n",
    "tmp.rename(columns={'opponentteamid':'teamid',\n",
    "                      'ytd_o_passingYardsPerAttempt_conceded':'ytd_passingYardsPerAttempt_conceded',\n",
    "                      'ytd_o_rushingYardsPerAttempt_conceded':'ytd_rushingYardsPerAttempt_conceded'}, inplace=True)\n",
    "\n",
    "yards_df = pd.merge(yards_df, tmp, on=['season', 'teamid', 'week'], how='left')\n",
    "\n",
    "# create opponents passing/rushing yards\n",
    "tmp = yards_df[['season','teamid','week','ytd_passingYardsPerAttempt','ytd_rushingYardsPerAttempt']]\n",
    "\n",
    "tmp.rename(columns={'teamid':'opponentteamid',\n",
    "                        'ytd_passingYardsPerAttempt':'ytd_o_passingYardsPerAttempt',\n",
    "                        'ytd_rushingYardsPerAttempt':'ytd_o_rushingYardsPerAttempt'}, inplace=True)\n",
    "\n",
    "yards_df = pd.merge(yards_df, tmp, on = ['season','week','opponentteamid'], how='left')\n",
    "\n",
    "yards_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge yards info into game_df\n",
    "\n",
    "print(game_df.shape)\n",
    "game_df = pd.merge(game_df, \n",
    "                   yards_df[['season','teamid','week',\n",
    "                             'ytd_passingYardsPerAttempt','ytd_rushingYardsPerAttempt',\n",
    "                             'ytd_passingYardsPerAttempt_conceded', 'ytd_rushingYardsPerAttempt_conceded',\n",
    "                             'ytd_o_passingYardsPerAttempt','ytd_o_rushingYardsPerAttempt',\n",
    "                             'ytd_o_passingYardsPerAttempt_conceded', 'ytd_o_rushingYardsPerAttempt_conceded']],\n",
    "                  on = ['season','teamid','week'], how='left')\n",
    "print(game_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3.2 ytd_scrambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = f'''\n",
    "select cast(season as integer) season, \n",
    "        teamid, eventmetadata.week week,\n",
    "       sum(totalscrambles) game_scrambles, 1 idx\n",
    "from datalakefootball.player_aggregated_game_stats\n",
    "where season >= '2013' and leagueid='8'\n",
    "group by season, teamid, eventmetadata.week\n",
    "order by season, teamid, week\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    scrambles_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(scrambles_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")\n",
    "    \n",
    "    \n",
    "# calculate cumulated sum and then yardsPerAttempt\n",
    "gd = scrambles_df.groupby(['season','teamid'])\n",
    "\n",
    "scrambles_df['ytd_scrambles'] = gd.game_scrambles.cumsum() / gd.idx.cumsum()\n",
    "\n",
    "scrambles_df['ytd_scrambles'] = gd.ytd_scrambles.shift(1)\n",
    "\n",
    "\n",
    "# merge scrambles into game_df\n",
    "game_df = pd.merge(game_df, scrambles_df[['season','teamid','week','ytd_scrambles']], \n",
    "                   on=['season','teamid','week'], how='left')\n",
    "\n",
    "game_df['ytd_scrambleRatio'] = game_df.ytd_scrambles / game_df.ytd_passPlaysPerGame\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Prepare baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create baseline case from ytd data\n",
    "\n",
    "baseline_df = game_df[['season','teamid','ytd_gameTime','ytd_pace','ytd_pace_conceded',\n",
    "                        'ytd_passingpercentage','ytd_offensivePlaysPerGame','ytd_passPlaysPerGame','ytd_TOPperGame']]\n",
    "baseline_df = baseline_df.groupby(['season','teamid']).tail(1)\n",
    "\n",
    "baseline_df.rename(columns={'ytd_gameTime':'base_gameTime',\n",
    "                              'ytd_pace':'base_pace', \n",
    "                              'ytd_pace_conceded':'base_pace_conceded',\n",
    "                              'ytd_offensivePlaysPerGame':'base_offensivePlaysPerGame',\n",
    "                              'ytd_passPlaysPerGame':'base_passPlaysPerGame',\n",
    "                              'ytd_passingpercentage':'base_passingpercentage',\n",
    "                              'ytd_TOPperGame':'base_TOPperGame'},\n",
    "                                inplace=True)\n",
    "\n",
    "baseline_df.season = baseline_df.season + 1\n",
    "\n",
    "# merge baseline info into game_df, in this case, we will lose 2013\n",
    "game_df = pd.merge(game_df, baseline_df, on=['season','teamid'], how='inner')\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute regressed YTD team passing %, using ytd and baseline info\n",
    "# compute expected passing play\n",
    "game_df['reg_passingpercentage'] = (350 * game_df.base_passingpercentage + \n",
    "                                    game_df.ytd_totalPlays * game_df.ytd_passingpercentage) / \\\n",
    "                                   (350 + game_df.ytd_totalPlays)\n",
    "game_df['exp_passingPlays'] = game_df.exp_totalPlays * game_df.reg_passingpercentage\n",
    "\n",
    "#plt.plot(game_df.exp_passingPlays[game_df.week > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add baseline info for opponent team\n",
    "\n",
    "tmp = game_df[['teamid','gamecode','ytd_TOPperGame','ytd_totalPointsPerGame','ytd_totalSacksPerGame',\n",
    "               'base_pace','base_pace_conceded','base_offensivePlaysPerGame','base_TOPperGame']].copy()\n",
    "tmp.rename(columns={'teamid':'opponentteamid',\n",
    "                    'ytd_TOPperGame':'ytd_o_TOPperGame',\n",
    "                    'ytd_totalPointsPerGame':'ytd_o_totalPointsPerGame',\n",
    "                    'ytd_totalSacksPerGame':'ytd_o_totalSacksPerGame',\n",
    "                    'base_pace':'base_o_pace',\n",
    "                    'base_pace_conceded':'base_o_pace_conceded',\n",
    "                    'base_offensivePlaysPerGame':'base_o_offensivePlaysPerGame',\n",
    "                    'base_passingpercentage':'base_o_passingpercentage',\n",
    "                    'base_TOPperGame':'base_o_TOPperGame'}, \n",
    "                       inplace=True)\n",
    "\n",
    "game_df = pd.merge(game_df, tmp, on = ['opponentteamid', 'gamecode'], how='left')\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 Pre-game odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = f'''\n",
    "WITH mainQuery AS\n",
    "(\n",
    "    WITH subQuery AS\n",
    "    (\n",
    "        SELECT\n",
    "            event.eventId AS eventId,\n",
    "            lineList.scope.name AS lineScope,\n",
    "            lineList.line AS lineData,\n",
    "            cast(season as integer) season,\n",
    "            eventmetadata.gamecode gamecode\n",
    "        FROM datalakefootball.odds,\n",
    "            UNNEST(event.lines) t(lineList)\n",
    "        WHERE leagueid='8'\n",
    "    )\n",
    "    SELECT\n",
    "        season,\n",
    "        gamecode,\n",
    "        eventId,\n",
    "        lineScope,\n",
    "        sublineList.lineType.name AS lineType,\n",
    "        sublineList.total AS overUnderPoints,\n",
    "        sublineList.favoritePoints,\n",
    "        sublineList.favoriteTeamId,\n",
    "        IF(sublineList.favoriteMoney='EVEN', 100.0, 1.0 * CAST(sublineList.favoriteMoney AS INTEGER)) AS favoriteMoney,\n",
    "        IF(sublineList.underdogMoney='EVEN', 100.0, 1.0 * CAST(sublineList.underdogMoney AS INTEGER)) AS underdogMoney,\n",
    "        IF(sublineList.homeMoney='EVEN', 100.0, 1.0 * CAST(sublineList.homeMoney AS INTEGER)) AS homeMoney,\n",
    "        IF(sublineList.awayMoney='EVEN', 100.0, 1.0 * CAST(sublineList.awayMoney AS INTEGER)) AS awayMoney,\n",
    "        IF(sublineList.overMoney='EVEN', 100.0, 1.0 * CAST(sublineList.overMoney AS INTEGER)) AS overMoney,\n",
    "        IF(sublineList.underMoney='EVEN', 100.0, 1.0 * CAST(sublineList.underMoney AS INTEGER)) AS underMoney\n",
    "    FROM subQuery,\n",
    "        UNNEST(lineData) t(sublineList)\n",
    ")\n",
    "SELECT\n",
    "    season,\n",
    "    gamecode, -- same as eventId\n",
    "    -- eventId,\n",
    "    -- lineScope,\n",
    "    -- lineType,\n",
    "    overUnderPoints,\n",
    "    favoritePoints,\n",
    "    favoriteTeamId,\n",
    "    -- favoriteMoney,\n",
    "    CASE\n",
    "        WHEN favoriteMoney < 0 THEN - (100 - favoriteMoney) / favoriteMoney\n",
    "        WHEN favoriteMoney > 0 THEN (100 + favoriteMoney) / 100\n",
    "    END AS favoriteMoneyDecimal,\n",
    "    -- underdogMoney,\n",
    "    CASE\n",
    "        WHEN underdogMoney < 0 THEN - (100 - underdogMoney) / underdogMoney\n",
    "        WHEN underdogMoney > 0 THEN (100 + underdogMoney) / 100\n",
    "    END AS underdogMoneyDecimal,\n",
    "    -- homeMoney,\n",
    "    CASE\n",
    "        WHEN homeMoney < 0 THEN - (100 - homeMoney) / homeMoney\n",
    "        WHEN homeMoney > 0 THEN (100 + homeMoney) / 100\n",
    "    END AS homeMoneyDecimal,\n",
    "    -- awayMoney,\n",
    "    CASE\n",
    "        WHEN awayMoney < 0 THEN - (100 - awayMoney) / awayMoney\n",
    "        WHEN awayMoney > 0 THEN (100 + awayMoney) / 100\n",
    "    END AS awayMoneyDecimal,\n",
    "    -- overMoney,\n",
    "    CASE\n",
    "        WHEN overMoney < 0 THEN - (100 - overMoney) / overMoney\n",
    "        WHEN overMoney > 0 THEN (100 + overMoney) / 100\n",
    "    END AS overMoneyDecimal,\n",
    "    -- underMoney,\n",
    "    CASE\n",
    "        WHEN underMoney < 0 THEN - (100 - underMoney) / underMoney\n",
    "        WHEN underMoney > 0 THEN (100 + underMoney) / 100\n",
    "    END AS underMoneyDecimal\n",
    "FROM mainQuery\n",
    "WHERE lineType = 'current' and season >= 2016\n",
    "order by season, gamecode\n",
    "'''\n",
    "\n",
    "if True:\n",
    "    odds_df = cursor.execute(simple_query).as_pandas()\n",
    "    print(odds_df.info())\n",
    "else:\n",
    "    print(\"Failed to query!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge odds into game_df\n",
    "\n",
    "tmp = game_df.loc[game_df.season >= 2016, ['gamecode','teamid','opponentteamid']].copy()\n",
    "\n",
    "tmp2 = odds_df[['gamecode','favoriteTeamId','homeMoneyDecimal','awayMoneyDecimal','favoritePoints']].copy()\n",
    "tmp2.loc[:,'odds'] = odds_df.homeMoneyDecimal / odds_df.awayMoneyDecimal\n",
    "\n",
    "tmp2 = pd.merge(tmp, tmp2[['gamecode','favoriteTeamId','odds','favoritePoints']], on=['gamecode'], how='left')\n",
    "\n",
    "id = tmp2.teamid == tmp2.favoriteTeamId\n",
    "tmp2.loc[id,'odds'] = 1 / tmp2.odds[id]\n",
    "\n",
    "tmp2.loc[id,  'favoritePoints'] = abs(tmp2.favoritePoints[id])\n",
    "tmp2.loc[~id, 'favoritePoints'] = -abs(tmp2.favoritePoints[~id])\n",
    "\n",
    "#tmp2.sort_values(['gamecode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge odds df into game_df\n",
    "game_df = pd.merge(game_df, tmp2[['gamecode','teamid','odds','favoritePoints']], on=['gamecode','teamid'], how='left')\n",
    "game_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Featuring preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we may want to re-calculate the expected total plays given the data issue with the 1st 5 weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 weighted historical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha controls the weighting factor calculation\n",
    "\n",
    "alpha = 2.0\n",
    "\n",
    "w = game_df.ytd_gameTime * alpha / (game_df.ytd_gameTime * alpha + game_df.base_gameTime)\n",
    "\n",
    "game_df['ytd_offensivePlaysPerGameAdj'] = game_df.ytd_offensivePlaysPerGame * w + game_df.base_offensivePlaysPerGame * (1-w)\n",
    "\n",
    "game_df['ytd_passPlaysPerGameAdj'] = game_df.ytd_passPlaysPerGame * w + game_df.base_passPlaysPerGame * (1-w)\n",
    "\n",
    "game_df['ytd_passRatioAdj'] = game_df['ytd_passPlaysPerGameAdj'] / game_df['ytd_offensivePlaysPerGameAdj']\n",
    "\n",
    "w_gameTime = (game_df.ytd_TOPperGame + game_df.ytd_o_TOPperGame) * w + \\\n",
    "                (game_df.base_TOPperGame + game_df.base_o_TOPperGame) * (1-w)\n",
    "\n",
    "# do we need this game time adjustment????\n",
    "#game_df['ytd_offensivePlaysAdj'] = 3600 / w_gameTime * game_df['ytd_offensivePlaysPerGameAdj']    \n",
    "game_df['ytd_offensivePlaysAdj'] = game_df['ytd_offensivePlaysPerGameAdj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 team pace adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pace = game_df.ytd_pace * w + game_df.base_pace * (1-w)\n",
    "w_pace_conceded = game_df.ytd_pace_conceded * w + game_df.base_pace_conceded * (1-w)\n",
    "\n",
    "w_o_pace = game_df.ytd_o_pace * w + game_df.base_o_pace * (1-w)\n",
    "w_o_pace_conceded = game_df.ytd_o_pace_conceded * w + game_df.base_o_pace_conceded * (1-w)\n",
    "\n",
    "# adjustment term by pace\n",
    "\n",
    "game_df['ytd_paceConcededAdj'] = w_o_pace - w_pace_conceded\n",
    " \n",
    "game_df['ytd_paceAdj'] = w_pace - w_o_pace_conceded  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 match-up specific historical TPPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df['ytd_passingYardsAdj'] = game_df.ytd_passingYardsPerAttempt - game_df.ytd_o_passingYardsPerAttempt\n",
    "game_df['ytd_rushingYardsAdj'] = game_df.ytd_rushingYardsPerAttempt - game_df.ytd_o_rushingYardsPerAttempt\n",
    "\n",
    "game_df['ytd_passingYardsAdj2'] = game_df.ytd_passingYardsPerAttempt - game_df.ytd_o_passingYardsPerAttempt_conceded\n",
    "game_df['ytd_rushingYardsAdj2'] = game_df.ytd_rushingYardsPerAttempt - game_df.ytd_o_rushingYardsPerAttempt_conceded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Features for TPPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for total plays\n",
    "num_fields = ['ytd_offensivePlaysAdj', \n",
    "              'ytd_paceAdj', \n",
    "              'ytd_paceConcededAdj', \n",
    "             ]\n",
    "\n",
    "features_TPPG = game_df[num_fields]\n",
    "\n",
    "id = ~features_TPPG.isna().any(axis=1)\n",
    "features_TPPG = features_TPPG[id]\n",
    "print(features_TPPG.shape)\n",
    "\n",
    "id_train = (game_df.season[id] <= 2018).tolist()\n",
    "id_test  = (game_df.season[id] == 2019).tolist()\n",
    "print(len(id_train), len(id_test))\n",
    "\n",
    "label_TPPG = game_df[id].totaloffensiveplays.astype(float)\n",
    "\n",
    "transform_pipeline = ColumnTransformer(transformers=[\n",
    "                                            ('num', StandardScaler(), num_fields),\n",
    "                                        ])\n",
    "\n",
    "features_TPPG = transform_pipeline.fit_transform(features_TPPG)\n",
    "\n",
    "\n",
    "feature_names = num_fields.copy()\n",
    "#cat_one_hot_fields = transform_pipeline.named_transformers_.cat.get_feature_names(input_features=cat_fields)\n",
    "#feature_names.extend(cat_one_hot_fields)\n",
    "print(\"Features:\", feature_names)\n",
    "\n",
    "if type(features_TPPG) == np.ndarray:\n",
    "    features_TPPG = pd.DataFrame(features_TPPG, columns=feature_names)\n",
    "else:\n",
    "    features_TPPG = pd.DataFrame(features_TPPG.toarray(), columns=feature_names)\n",
    "    \n",
    "\n",
    "# split data into train(2014~2018), test(2019)\n",
    "features_TPPG_train = features_TPPG[id_train]\n",
    "features_TPPG_test  = features_TPPG[id_test]\n",
    "\n",
    "label_TPPG_train = label_TPPG[id_train]\n",
    "label_TPPG_test  = label_TPPG[id_test]\n",
    "\n",
    "print(features_TPPG_train.shape, label_TPPG_train.shape, features_TPPG_test.shape, label_TPPG_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Features for team pass ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pass ratio\n",
    "num_fields = ['ytd_passRatioAdj',\n",
    "              'ytd_scrambles',\n",
    "              'ytd_scrambleRatio',\n",
    "             #'odds',\n",
    "             'favoritePoints',\n",
    "             'ytd_passingYardsPerAttempt',\n",
    "             'ytd_rushingYardsPerAttempt',\n",
    "             'ytd_o_passingYardsPerAttempt',\n",
    "             'ytd_o_rushingYardsPerAttempt',\n",
    "             'ytd_passingYardsPerAttempt_conceded',\n",
    "             'ytd_rushingYardsPerAttempt_conceded',\n",
    "             'ytd_o_passingYardsPerAttempt_conceded',\n",
    "             'ytd_o_rushingYardsPerAttempt_conceded',\n",
    "             ]\n",
    "              \n",
    "features_pass_ratio = game_df[num_fields]\n",
    "\n",
    "print(features_pass_ratio.shape)\n",
    "id = ~features_pass_ratio.isna().any(axis=1)\n",
    "features_pass_ratio = features_pass_ratio[id]\n",
    "print(features_pass_ratio.shape)\n",
    "\n",
    "id_train = (game_df.season[id] <= 2018).tolist()\n",
    "id_test  = (game_df.season[id] == 2019).tolist()\n",
    "print(len(id_train), len(id_test))\n",
    "\n",
    "label_pass_ratio = (game_df[id].totaldesignedpassplays.astype(float) / game_df[id].totaloffensiveplays).astype(float)\n",
    "\n",
    "transform_pipeline = ColumnTransformer(transformers=[\n",
    "                                            ('num', StandardScaler(), num_fields),\n",
    "                                        ])\n",
    "\n",
    "features_pass_ratio = transform_pipeline.fit_transform(features_pass_ratio)\n",
    "\n",
    "feature_names = num_fields.copy()\n",
    "#cat_one_hot_fields = transform_pipeline.named_transformers_.cat.get_feature_names(input_features=cat_fields)\n",
    "#feature_names.extend(cat_one_hot_fields)\n",
    "print(\"Features:\", feature_names)\n",
    "\n",
    "if type(features_pass_ratio) == np.ndarray:\n",
    "    features_pass_ratio = pd.DataFrame(features_pass_ratio, columns=feature_names)\n",
    "else:\n",
    "    features_pass_ratio = pd.DataFrame(features_pass_ratio.toarray(), columns=feature_names)\n",
    "    \n",
    "\n",
    "# split data into train(2014~2018), test(2019)\n",
    "features_pass_ratio_train = features_pass_ratio[id_train]\n",
    "features_pass_ratio_test  = features_pass_ratio[id_test]\n",
    "\n",
    "label_pass_ratio_train = label_pass_ratio[id_train]\n",
    "label_pass_ratio_test  = label_pass_ratio[id_test]\n",
    "\n",
    "print(features_pass_ratio_train.shape, label_pass_ratio_train.shape, \n",
    "      features_pass_ratio_test.shape, label_pass_ratio_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = make_scorer(mean_absolute_error)\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Team expected total plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 simple ytd model vs. benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = (game_df.season <= 2018) & (game_df.week > 5)\n",
    "\n",
    "mse_1 = np.abs((game_df.totaloffensiveplays - game_df.ytd_offensivePlaysPerGame)[id]).mean()\n",
    "\n",
    "mse_2 = np.abs((game_df.totaloffensiveplays - game_df.exp_totalPlays)[id]).mean()\n",
    "\n",
    "print('ytd_TPPP model MAE:  {:.2f}'.format(mse_1))\n",
    "print('Benchmark model MAE: {:.2f}'.format(mse_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(game_df.totaloffensiveplays - game_df.exp_totalPlays)[id].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 simple ytd_n model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, ytd_n calculated this way is not normalized\n",
    "\n",
    "id = (game_df.season <= 2018)\n",
    "tmp = game_df[id].copy()\n",
    "\n",
    "gd = tmp.groupby(by=['season','teamid'])\n",
    "tmp['ytd_1_offensivePlaysPerGame'] = gd['totaloffensiveplays_normalized'].shift(1).rolling(1).mean()\n",
    "tmp['ytd_2_offensivePlaysPerGame'] = gd['totaloffensiveplays_normalized'].shift(1).rolling(2).mean()\n",
    "tmp['ytd_3_offensivePlaysPerGame'] = gd['totaloffensiveplays_normalized'].shift(1).rolling(3).mean()\n",
    "tmp['ytd_4_offensivePlaysPerGame'] = gd['totaloffensiveplays_normalized'].shift(1).rolling(4).mean()\n",
    "tmp['ytd_5_offensivePlaysPerGame'] = gd['totaloffensiveplays_normalized'].shift(1).rolling(5).mean()\n",
    "\n",
    "print('ytd_1 case: {:.2f}'.format(np.abs((tmp.totaloffensiveplays - tmp.ytd_1_offensivePlaysPerGame)).mean()) )\n",
    "print('ytd_2 case: {:.2f}'.format(np.abs((tmp.totaloffensiveplays - tmp.ytd_2_offensivePlaysPerGame)).mean()) )\n",
    "print('ytd_3 case: {:.2f}'.format(np.abs((tmp.totaloffensiveplays - tmp.ytd_3_offensivePlaysPerGame)).mean()) )\n",
    "print('ytd_4 case: {:.2f}'.format(np.abs((tmp.totaloffensiveplays - tmp.ytd_4_offensivePlaysPerGame)).mean()) )\n",
    "print('ytd_5 case: {:.2f}'.format(np.abs((tmp.totaloffensiveplays - tmp.ytd_5_offensivePlaysPerGame)).mean()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = SGDRegressor(max_iter=10000, tol=1e-6, random_state=42)\n",
    "#model_linear = LinearRegression()\n",
    "\n",
    "MAE_linear = cross_val_score(model_linear, features_TPPG_train, label_TPPG_train, cv=folds, scoring=MAE)\n",
    "print('Linear regression model MAE: {:.3f}'.format(np.mean(MAE_linear)) )\n",
    "\n",
    "model_svr = LinearSVR(max_iter=10000, tol=1e-6, random_state=42)\n",
    "MAE_svr = cross_val_score(model_svr, features_TPPG_train, label_TPPG_train, cv=folds, scoring=MAE)\n",
    "print('SV regression MAE: {:.3f}'.format(np.mean(MAE_svr)))\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=500, max_depth=5, random_state=42)\n",
    "MAE_rf = cross_val_score(model_rf, features_TPPG_train, label_TPPG_train, cv=folds, scoring=MAE)\n",
    "print('random forest regression MAE: {:.3f}'.format(np.mean(MAE_rf)) )\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.5, learning_rate = 0.1, booster='gbtree',\n",
    "                max_depth = 5, alpha = 10, n_estimators = 50)\n",
    "MAE_xgb = cross_val_score(model_xgb, features_TPPG_train, label_TPPG_train, cv=folds, scoring=MAE)\n",
    "print('XGBoost regression MAE: {:.3f}'.format(np.mean(MAE_xgb)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model interpretation\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "mod = sm.OLS(np.array(label_train), np.array(features_train), missing='drop')\n",
    "res = mod.fit()\n",
    "\n",
    "mae = np.abs(res.resid).mean()\n",
    "\n",
    "print('{:.2f}'.format(mae) )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Team expected passing ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark case\n",
    "# there is a mis-match: expected value is normalized\n",
    "\n",
    "id = (game_df.season <= 2018) & (game_df.week > 5)\n",
    "\n",
    "mse_1 = np.abs((game_df.totaldesignedpassplays - game_df.ytd_passPlaysPerGame)[id] / game_df.totaloffensiveplays[id]).mean()\n",
    "\n",
    "mse_2 = np.abs((game_df.totaldesignedpassplays - game_df.ytd_passPlaysPerGameAdj)[id] / game_df.totaloffensiveplays[id]).mean()\n",
    "\n",
    "mse_3 = np.abs((game_df.totaldesignedpassplays - game_df.exp_passingPlays)[id] / game_df.totaloffensiveplays[id]).mean()\n",
    "\n",
    "print('average_passRatio: {:.3f}\\n'.format(label_pass_ratio_train.mean()))\n",
    "\n",
    "print('ytd_passRatio model MAE: {:.3f}'.format(mse_1))\n",
    "print('w_passRatio model MAE:   {:.3f}'.format(mse_2))\n",
    "print('Benchmark model MAE:     {:.3f}'.format(mse_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = SGDRegressor(max_iter=10000, tol=1e-6)\n",
    "\n",
    "MAE_linear = cross_val_score(model_linear, features_pass_ratio_train, label_pass_ratio_train, cv=folds, scoring=MAE)\n",
    "print('Linear regression model MAE: {:.4f}'.format(np.mean(MAE_linear)) )\n",
    "\n",
    "model_svr = LinearSVR(max_iter=10000, tol=1e-3)\n",
    "MAE_svr = cross_val_score(model_svr, features_pass_ratio_train, label_pass_ratio_train, cv=folds, scoring=MAE)\n",
    "print('SV regression MAE: {:.4f}'.format(np.mean(MAE_svr)))\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=0)\n",
    "MAE_rf = cross_val_score(model_rf, features_pass_ratio_train, label_pass_ratio_train, cv=folds, scoring=MAE)\n",
    "print('random forest regression MAE: {:.4f}'.format(np.mean(MAE_rf)) )\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.5, learning_rate = 0.1, booster='gbtree',\n",
    "                max_depth = 5, alpha = 10, n_estimators = 50)\n",
    "MAE_xgb = cross_val_score(model_xgb, features_pass_ratio_train, label_pass_ratio_train, cv=folds, scoring=MAE)\n",
    "print('XGBoost regression MAE: {:.4f}'.format(np.mean(MAE_xgb)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Team total plays per game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline case\n",
    "id = (game_df.season > 2018) & (game_df.week > 5)\n",
    "\n",
    "mse_1 = np.abs((game_df.totaloffensiveplays - game_df.ytd_offensivePlaysPerGame)[id]).mean()\n",
    "\n",
    "mse_2 = np.abs((game_df.totaloffensiveplays - game_df.exp_totalPlays)[id]).mean()\n",
    "\n",
    "print('ytd_TPPP model MAE:  {:.3f}'.format(mse_1))\n",
    "print('Benchmark model MAE: {:.3f}'.format(mse_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "model_linear.fit(features_TPPG_train, label_TPPG_train)\n",
    "mae = np.abs(model_linear.predict(features_TPPG_test) - label_TPPG_test).mean()\n",
    "print('linear regression MAE: {:.3f}'.format(mae) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm model\n",
    "model_svr.fit(features_TPPG_train, label_TPPG_train)\n",
    "mae = np.abs(model_svr.predict(features_TPPG_test) - label_TPPG_test).mean()\n",
    "print('SVM regression MAE: {:.3f}'.format(mae) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "model_rf.fit(features_TPPG_train, label_TPPG_train)\n",
    "mae = np.abs(model_rf.predict(features_TPPG_test) - label_TPPG_test).mean()\n",
    "print('random forest regression MAE: {:.3f}'.format(mae) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost\n",
    "model_xgb.fit(features_TPPG_train, label_TPPG_train)\n",
    "\n",
    "label_hat = model_xgb.predict(features_TPPG_test)\n",
    "mae = np.abs(label_hat - np.array(label_TPPG_test)).mean()\n",
    "\n",
    "print('gradient boost regression MAE: {:.3f}'.format(mae) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pass Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline case\n",
    "id = (game_df.season > 2018) & (game_df.week > 5)\n",
    "\n",
    "mse_1 = np.abs((game_df.totaldesignedpassplays - game_df.ytd_passPlaysPerGame)[id] / game_df.totaloffensiveplays[id]).mean()\n",
    "mse_2 = np.abs((game_df.totaldesignedpassplays - game_df.ytd_passPlaysPerGameAdj)[id] / game_df.totaloffensiveplays[id]).mean()\n",
    "mse_3 = np.abs((game_df.totaldesignedpassplays - game_df.exp_passingPlays)[id] / game_df.totaloffensiveplays[id]).mean()\n",
    "\n",
    "print('average_passRatio: {:.3f}\\n'.format(label_train.mean()))\n",
    "\n",
    "#print('ytd_passRatio model MAE: {:.3f}'.format(mse_1))\n",
    "#print('w_passRatio model MAE:   {:.3f}'.format(mse_2))\n",
    "print('Benchmark model MAE:          {:.3f}'.format(mse_3))\n",
    "\n",
    "MAE_linear = cross_val_score(model_linear, features_test_s, label_test, cv=folds, scoring=MAE)\n",
    "print('Linear regression model MAE:  {:.3f}'.format(np.mean(MAE_linear)) )\n",
    "\n",
    "MAE_svr = cross_val_score(model_svr, features_test_s, label_test, cv=folds, scoring=MAE)\n",
    "print('SV regression MAE:            {:.3f}'.format(np.mean(MAE_svr)))\n",
    "\n",
    "MAE_rf = cross_val_score(model_rf, features_test, label_test, cv=folds, scoring=MAE)\n",
    "print('random forest regression MAE: {:.3f}'.format(np.mean(MAE_rf)) )\n",
    "\n",
    "MAE_xgb = cross_val_score(model_xgb, features_test, label_test, cv=folds, scoring=MAE)\n",
    "print('XGBoost regression MAE:       {:.3f}'.format(np.mean(MAE_xgb)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl-usage-models",
   "language": "python",
   "name": "nfl-usage-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
